# -*- coding: utf-8 -*-
"""DecisionTreeDenemesi.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JiZTUVDUF2bSlnL0aP_oYbP1upcaBmfv
"""

import pandas as pd
import numpy as np

#column_names = ["date", "plant-stand", "precip", "temp", "hail", "crop-hist", "area-damaged", "severity", "seed-tmt", "germination", "plant-growth", "leaves", "leafspots-halo", "leafspots-marg", "leafspot-size", "leaf-shread", "leaf-malf", "leaf-mild", "stem", "lodging", "stem-cankers", "canker-lesion", "fruiting-bodies", "external-decay", "mycelium", "int-discolor", "sclerotia", "fruit-pods", "fruit-spots", "seed", "mold-growth", "seed-discolor","seed-size", "shriveling", "roots",  "target"]


# Train Data
train_data = pd.read_csv('soybean-small-2.csv')

# Bağımsız değişkenler ve hedef değişkeni ayırın
#X = data.drop("target", axis=1)  # Bağımsız değişkenler
#y = data["target"]  # Hedef değişken

# Eğitim veri setini ayrı dosyalara kaydetme
X_train = train_data.drop(columns=["class"])
y_train = train_data["class"]

print("X_train length",str(len(X_train)) +"\n"+ "y_train length",str(len(y_train)))

# Veri kümesinin entropisini hesaplayan fonksiyon
def entropy_hesapla(y):
    unique_classes, class_counts = np.unique(y, return_counts=True) # kaç farklı class olduğunu ve bu classlardan kaç tane olduğunu hesaplar
    probabilities = class_counts / len(y)   # her classın veri kümesindeki oranını hesaplar
    entropy_value = -np.sum(probabilities * np.log2(probabilities))  # entropi hesaplar
    return entropy_value

# Belirli bir feature için information gain hesaplayan fonksiyon
def information_gain_hesapla(X, y, feature):
    entropy_before = entropy_hesapla(y) # mevcut durumun entropisini hesaplar
    unique_values = np.unique(X[feature]) # feature'daki unique değerleri alır
    information_after = 0

    for value in unique_values:  # her bir unique değer için
        subset_y = y[X[feature] == value]  # feature'ın bu değere sahip olduğu alt kümesi
        information_after += len(subset_y) / len(y) * entropy_hesapla(subset_y)  # information'ı hesaplar

    information_gain_value = entropy_before - information_after   # information gain'i hesaplar
    return information_gain_value

# En iyi bölünme noktasını bulan fonksiyon (Gain'e bakarak)
def find_best_split(X, y):
    best_feature = None # en iyi feature için başlangıç değeri
    best_information_gain = 0 # en iyi information gain için başlangıç değeri

    for feature in X.columns: # verilen her bir feature için information gain hesaplar
        current_information_gain = information_gain_hesapla(X, y, feature)
        if current_information_gain > best_information_gain:   # current information gain, şu ana kadar en iyisiyse best feature'ı güncelle
            best_information_gain = current_information_gain
            best_feature = feature

    return best_feature # best feature'ı döndürür

# ID3 Algoritmasını kullanarak Decision Tree (Karar Ağacı) oluşturan fonksiyon.
def id3_build_tree(X, y):

    if len(np.unique(y)) == 1: # eğer veri kümesinde yalnızca bir class varsa, bir leaf node oluştur ve class'ı döndür
        return {'class': y.iloc[0]}

    best_feature = find_best_split(X, y)  # best feature'u bulur (gain'e göre)

    if best_feature is None:  # eğer best feature'u yoksa, bir leaf node oluştur ve en çok tekrar eden class'ı döndür
        return {'class': np.argmax(np.bincount(y))}

    tree = {'feature': best_feature, 'branches': {}}  # ağacı oluştur

    for value in np.unique(X[best_feature]):   # best feature'un her bir unique değeri için sub tree oluşturur
        subset_X = X[X[best_feature] == value].drop(best_feature, axis=1)
        subset_y = y[X[best_feature] == value]

        tree['branches'][value] = id3_build_tree(subset_X, subset_y)  # sub tree oluşturur ve ana tree'nin alt dallarına ekler (recursive devam eder işlemler)

    return tree

#Karar ağacını kullanarak bir test data için tahmin yapar.
def predict(tree, sample):
    if 'class' in tree:  # eğer bu düğüm bir leaf node ise, class'ı döndür
        return tree['class']

    feature_value = sample[tree['feature']]
    if feature_value not in tree['branches']:  # feature'ın değeri ağaçta yoksa, "None" döndür
        return None

    branch = tree['branches'][feature_value]
    return predict(branch, sample) # tahminler ağacın geri kalanı için recursive şekilde devam eder

# Karar ağacını çizen fonksiyon
def print_tree(tree, indent=0):
    if "class" in tree:
        print("|__ Sınıf:", tree["class"])
    else:
        print("|__ Özellik:", tree["feature"])
        for value, subtree in tree["branches"].items():
            print("|    " * indent + "|__ {}: ".format(value), end="")
            print_tree(subtree, indent + 1)

from copy import deepcopy

# Her bir örneğin tahminlerini saklayacak dizi
predictions = []
# Her bir örneğin ağacının değişip değişmediğini saklayacak dizi
tree_changes = []
# İlk modeli oluşturma
model = id3_build_tree(X_train, y_train)

print("ilk model (47 data içeren)")
print(print_tree(model))

# Dosyayı açarak, içeriği silip yeniden yazma
file = open("models.txt", "w")
file.write("")
file.close()

model_file = open("models.txt", "a")  # Mevcut dosyayı eklemek için "a" kipi kullanılır
model_file.write("0 \n"+ str(model)+"\n")
model_file.close()


# Eğitim veri setindeki her bir örneği kullanarak işlemleri gerçekleştirme
for i in range(len(X_train)):
    # Veri setinden bir örneği çıkarıp test verisi olarak kullanma
    test_sample = X_train.iloc[i]
    test_label = y_train.iloc[i]

    # Bir örneği çıkarılmış veri seti ile modeli oluşturma
    reduced_X_train = X_train.copy().drop(index=X_train.index[i])
    reduced_y_train = y_train.copy().drop(index=y_train.index[i])
    new_model = id3_build_tree(reduced_X_train, reduced_y_train)

    # Test verisi üzerinde tahmin yapma
    prediction = predict(new_model, test_sample)

    # Tahminle gerçek etiketi karşılaştırma ve sonucu predictions dizisine ekleme
    if prediction == y_train.values[0]:
        predictions.append(True)
    else:
        predictions.append(False)

    # Oluşturulan ağaçları string olarak temsil ederek karşılaştırma
    #istenen verilen gerçekten silinmesi olayının kontrol edildiği yer.
    prev_model_str = str(model)
    new_model_str = str(new_model)

    # Treeler
    print(i+1)
    print(print_tree(new_model))
    print(prev_model_str == new_model_str)

    # Ağaçlar arasında değişiklik var mı kontrolü
    if prev_model_str != new_model_str:
        tree_changes.append(True)
    else:
        tree_changes.append(False)

    # Oluşturulan ağacın string temsilini alarak dosyaya yazma
    model_file = open("models.txt", "a")  # Mevcut dosyayı eklemek için "a" kipi kullanılır
    model_file.write(str(i+1)+"\n")
    model_file.write(new_model_str +"\n")
    model_file.close()

    # Modeli güncelleme (prev-next olayını sağlıyor.)
    model = new_model

# Tahmin sonuçları
print("Tahminler:")
print(predictions)

# Ağaç değişiklikleri
print("Ağaç Değişiklikleri var mı:")
print(tree_changes)

print("Predictions Array Length:", len(predictions))
print("Ağaç Değişiklikleri Array Length:", len(tree_changes))

def accuracy_hesapla(predictions):
    true_count = sum(predictions)
    total_count = len(predictions)
    percentage = (true_count / total_count) * 100
    return percentage

accuracy_hesapla(predictions)

import matplotlib.pyplot as plt
import seaborn as sns

# Verileri hazırlama
indices = list(range(1, len(predictions) + 1))

# Grafik ayarları
plt.figure(figsize=(12, 6))

# Tahmin sonuçları grafiği
plt.subplot(2, 1, 1)
sns.lineplot(x=indices, y=predictions, marker='o')
plt.title('Prediction Results')
plt.xlabel('Data Index')
plt.ylabel('Is the Prediction Correct?')
plt.xticks(indices)

# Ağaç değişiklikleri grafiği
plt.subplot(2, 1, 2)
sns.lineplot(x=indices, y=tree_changes, marker='o', color='r')
plt.title('Tree Changes')
plt.xlabel('Data Index')
plt.ylabel('Has the Tree Changed?')
plt.xticks(indices)

# Grafiklerin gösterimi
plt.tight_layout()

# Grafiklerin PNG dosyası olarak kaydedilmesi
plt.savefig('model_changes.png')

plt.show()

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

# Tahmin ve ağaç değişiklik verilerini örnek olarak oluşturuyoruz
predictions = [True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]
tree_changes = [False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]

# Veri seti büyüklüğü
n = len(predictions)

# Verileri görselleştirme
fig, axes = plt.subplots(3, 1, figsize=(12, 18))

# 1. Grafik: Predictions sonuçları için çubuk grafiği
axes[0].bar(range(n), predictions, color='blue', alpha=0.7)
axes[0].set_title('Predictions Results')
axes[0].set_xlabel('Sample Index')
axes[0].set_ylabel('Prediction Correct (1) or Incorrect (0)')
axes[0].set_xticks(range(n))
axes[0].set_yticks([0, 1])
axes[0].set_yticklabels(['False', 'True'])

# 2. Grafik: Tree changes sonuçları için çubuk grafiği
axes[1].bar(range(n), tree_changes, color='green', alpha=0.7)
axes[1].set_title('Tree Changes')
axes[1].set_xlabel('Sample Index')
axes[1].set_ylabel('Tree Changed (1) or Not (0)')
axes[1].set_xticks(range(n))
axes[1].set_yticks([0, 1])
axes[1].set_yticklabels(['No', 'Yes'])

# 3. Grafik: Heatmap ile predictions ve tree_changes
heatmap_data = np.array([predictions, tree_changes])
sns.heatmap(heatmap_data, annot=True, fmt="d", cmap="YlGnBu", ax=axes[2])
axes[2].set_title('Predictions and Tree Changes Heatmap')
axes[2].set_xlabel('Sample Index')
axes[2].set_yticks([0.5, 1.5])
axes[2].set_yticklabels(['Predictions', 'Tree Changes'])
axes[2].set_xticks(range(n))

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
# Preditions ve tree_changes dizilerinin uzunluğunu kontrol etme
print("Predictions Array Length:", len(predictions))
print("Ağaç Değişiklikleri Array Length:", len(tree_changes))

# X ekseni için örnek indeksleri
indices = list(range(1, len(predictions) + 1))

# Grafik oluşturma
plt.figure(figsize=(12, 6))

# Tahmin doğruluğunu çizme
plt.plot(indices, predictions, marker='o', linestyle='-', color='b', label='True Predictions')

# Ağaç değişikliklerini çizme
plt.plot(indices, tree_changes, marker='x', linestyle='--', color='r', label='Tree Changes')

# Grafiği özelleştirme
plt.xlabel('Smaple Index')
plt.ylabel('State')
plt.title('Model Changes and Prediction Accuracy')
plt.legend()
plt.grid(True)
plt.xticks(indices)

# Grafik gösterimi
plt.show()